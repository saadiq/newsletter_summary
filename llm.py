import os\nimport re\nimport anthropic\nimport datetime\n# Add OpenAI import\ntry:\n    import openai\nexcept ImportError:\n    openai = None\nfrom yaspin import yaspin\nfrom utils import clean_body\n# Add requests for OpenRouter API\nimport requests\nimport json\n\ndef analyze_newsletters_unified(newsletters, num_topics=10, provider='openai'):\n    \"\"\"\n    Process newsletters in a single step - identifying topics and generating summaries.\n    Now with OpenRouter support.\n    \n    Args:\n        newsletters: List of newsletter dictionaries\n        num_topics: Number of topics to identify and summarize (default: 10)\n        provider: 'openai' or 'claude'\n        \n    Returns:\n        Tuple of (analysis_text, extracted_topic_titles)\n    \"\"\"\n    # Prepare newsletter content\n    content_parts = []\n    \n    for i, nl in enumerate(newsletters, 1):\n        clean_content = clean_body(nl['body'], nl.get('body_format'))\n        \n        # Add structured newsletter entry with metadata\n        content_parts.append(\n            f\"NEWSLETTER #{i}\\n\"\n            f\"SUBJECT: {nl['subject']}\\n\"\n            f\"SENDER: {nl['sender']}\\n\"\n            f\"DATE: {nl['date']}\\n\"\n            f\"CONTENT:\\n{clean_content[:3000]}...\\n\\n\"  # Truncate to manage token usage\n        )\n    \n    newsletter_content = \"\\n\".join(content_parts)\n    \n    # Build comprehensive prompt with source and link requirements\n    prompt = f\"\"\"\nAnalyze these AI newsletters and identify the {num_topics} most significant and distinct topics.\n\nFor each topic:\n1. Create a clear, concise headline\n2. Provide \"What's New\" - a brief description of the development\n3. Explain \"Why It Matters\" for regular people in their daily lives\n4. Suggest \"Practical Impact\" with 2-3 specific actions people can take\n5. At the end of each topic, add:\n   - A line starting with \"**Source:**\" that lists the newsletter(s) where this information came from (e.g., \"**Source:** The Neuron, TLDR AI\")\n   - If available, add a line \"ðŸ”— [Visit Website](URL)\" with a direct link to the product, model, paper, or announcement being discussed (NOT a link to the newsletter itself)\n\nFormat your response with markdown:\n\n### 1. [Topic Headline]\n**What's New:** [Brief description of the development]\n\n**Why It Matters:** [Explanation for regular users]\n\n**Practical Impact:** [2-3 specific actions or opportunities]\n\n**Source:** [Newsletter names that covered this topic]\n\nðŸ”— [Visit Website](https://link-to-actual-product-or-announcement)\n\n### 2. [Next Topic]\n...and so on\n\nGUIDELINES:\n- Identify exactly {num_topics} topics unless there aren't enough distinct topics in the content\n- Sort topics by importance (most important first)\n- Focus on substantive developments, not newsletter metadata or advertisements\n- Ensure topics are distinct from each other (avoid multiple topics about the same subject)\n- Prioritize recent developments, major product launches, policy changes, or significant research\n- Focus on topics relevant to regular people, not just AI researchers or specialists\n- \"Why It Matters\" should explain real-world implications, not just industry impact\n- \"Practical Impact\" must be truly actionable - what can regular people DO with this information?\n- For \"Source\" information, list the actual newsletter names (e.g., \"The Neuron\", \"TLDR AI\", \"AI Breakfast\")\n- For links, include URLs to the actual products/announcements when available, not to the newsletters\n\nNEWSLETTER CONTENT:\n{newsletter_content}\n\"\"\"\n    \n    # Check if we should use OpenRouter\n    use_openrouter = os.environ.get(\"USE_OPENROUTER\", \"true\").lower() in (\"true\", \"1\", \"yes\")\n    \n    # Call the appropriate LLM\n    analysis_text = \"\"\n    if use_openrouter:\n        print(\"Using OpenRouter for unified analysis\")\n        analysis_text = analyze_with_openrouter(prompt, provider)\n    else:\n        if provider == 'openai':\n            client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n            response = client.chat.completions.create(\n                model=\"gpt-4.1-2025-04-14\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are an AI consultant helping summarize AI newsletter content for regular people.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n            )\n            analysis_text = response.choices[0].message.content\n        else:\n            anthropic_client = anthropic.Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n            response = anthropic_client.messages.create(\n                model=\"claude-3-7-sonnet-20250219\",\n                max_tokens=3000,\n                system=\"You are an AI consultant helping summarize AI newsletter content for regular people.\",\n                messages=[\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n            )\n            analysis_text = response.content[0].text\n    \n    # Extract topic titles from the analysis for report metadata\n    topic_titles = re.findall(r'###\\s*\\d+\\.\\s*(.*?)\\n', analysis_text)\n    \n    return analysis_text, topic_titles\n\ndef analyze_with_openrouter(prompt, model_provider):\n    \"\"\"\n    Route LLM requests through OpenRouter while maintaining the original provider choice.\n    \n    Args:\n        prompt: The prompt to send to the LLM\n        model_provider: 'claude' or 'openai' to determine which model to use\n    \n    Returns:\n        The LLM response\n    \"\"\"\n    openrouter_api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n    if not openrouter_api_key:\n        raise ValueError(\"OPENROUTER_API_KEY environment variable is required\")\n    \n    # Map provider to actual OpenRouter model ID\n    model_map = {\n        'claude': \"anthropic/claude-3-7-sonnet\",\n        'openai': \"openai/gpt-4.1\"\n    }\n    \n    if model_provider not in model_map:\n        raise ValueError(f\"Unknown model provider: {model_provider}\")\n    \n    model = model_map[model_provider]\n    \n    # Prepare the system message based on the provider\n    system_message = \"You are an AI consultant helping summarize AI newsletter content for regular people. Your primary goal is to identify the MOST SIGNIFICANT developments across different domains of AI, based on what appears in the newsletters being analyzed. When writing headlines, focus on the substantive development rather than secondary features or demonstrations (e.g., 'Anthropic Launches Claude 3.7' rather than 'Claude AI Plays PokÃ©mon'). Make the 'Why It Matters' section relevant to everyday life, and ensure the 'Practical Impact' section provides specific, actionable advice that regular people can implement. Be sure to include brand new developments (even if only mentioned in 1-2 newsletters) if they appear to be significant. Format your response with markdown headings and sections. For each topic, include source information and relevant links to the actual products/announcements. IMPORTANT: Ignore or exclude any sponsored, advertorial, or ad content when identifying and summarizing key developments. Do not include advertisers or sponsors as top content, even if they appear frequently.\"\n    \n    headers = {\n        \"Authorization\": f\"Bearer {openrouter_api_key}\",\n        \"HTTP-Referer\": \"https://github.com/saadiq/newsletter_summary\",  # Your application URL\n        \"X-Title\": \"AI Newsletter Summarizer\",  # Your application name\n        \"Content-Type\": \"application/json\"\n    }\n    \n    data = {\n        \"model\": model,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    }\n    \n    # Add tracing tags for cost analysis\n    data[\"transforms\"] = [\"middle-out\"]  # Enable detailed token breakdowns\n    current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n    data[\"route\"] = f\"newsletter_summary_{current_datetime}\"  # For cost tracking\n    \n    response = requests.post(\n        \"https://openrouter.ai/api/v1/chat/completions\",\n        headers=headers,\n        data=json.dumps(data)\n    )\n    \n    if response.status_code != 200:\n        raise Exception(f\"Error from OpenRouter API: {response.text}\")\n    \n    result = response.json()\n    \n    # Log usage information\n    if 'usage' in result:\n        tokens = result['usage']['total_tokens']\n        # Optional: Save detailed cost data\n        cost_log = {\n            \"timestamp\": datetime.datetime.now().isoformat(),\n            \"model\": model,\n            \"provider\": model_provider,\n            \"prompt_tokens\": result['usage'].get('prompt_tokens', 0),\n            \"completion_tokens\": result['usage'].get('completion_tokens', 0),\n            \"total_tokens\": tokens,\n            \"cost\": result['usage'].get('cost', 0)\n        }\n        \n        log_cost_data(cost_log)\n        \n        print(f\"OpenRouter call: {tokens} tokens used with {model}\")\n        if 'cost' in result['usage']:\n            print(f\"Estimated cost: ${result['usage']['cost']}\")\n    \n    return result['choices'][0]['message']['content']\n\ndef log_cost_data(cost_data):\n    \"\"\"Save cost data to a JSON file for later analysis\"\"\"\n    log_file = os.environ.get(\"OPENROUTER_COST_LOG\", \"openrouter_costs.json\")\n    \n    # Create or append to the log file\n    if os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            try:\n                existing_data = json.load(f)\n            except json.JSONDecodeError:\n                existing_data = []\n    else:\n        existing_data = []\n    \n    existing_data.append(cost_data)\n    \n    with open(log_file, 'w') as f:\n        json.dump(existing_data, f, indent=2)\n\ndef analyze_with_fallback(prompt, provider='openai'):\n    \"\"\"Try OpenRouter first, fall back to direct API if there's an error\"\"\"\n    try:\n        # Try OpenRouter\n        return analyze_with_openrouter(prompt, provider)\n    except Exception as e:\n        print(f\"Error using OpenRouter: {str(e)}\")\n        print(\"Falling back to direct API call...\")\n        \n        # Force direct API mode temporarily\n        old_setting = os.environ.get(\"USE_OPENROUTER\", \"true\")\n        os.environ[\"USE_OPENROUTER\"] = \"false\"\n        \n        try:\n            # Use direct API\n            result = analyze_with_llm_direct(prompt, [], provider)\n            return result\n        finally:\n            # Restore setting\n            os.environ[\"USE_OPENROUTER\"] = old_setting\n\ndef check_openrouter_status():\n    \"\"\"Check if OpenRouter is operational and your account is properly configured\"\"\"\n    openrouter_api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n    if not openrouter_api_key:\n        return False, \"OPENROUTER_API_KEY environment variable not set\"\n    \n    headers = {\n        \"Authorization\": f\"Bearer {openrouter_api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    try:\n        response = requests.get(\n            \"https://openrouter.ai/api/v1/auth/key\",\n            headers=headers\n        )\n        \n        if response.status_code == 200:\n            data = response.json()\n            return True, f\"OpenRouter configured correctly. Rate limit: {data.get('rate_limit', 'unknown')}, remaining: {data.get('rate_limit_remaining', 'unknown')}\"\n        else:\n            return False, f\"OpenRouter API error: {response.text}\"\n    except Exception as e:\n        return False, f\"Error checking OpenRouter status: {str(e)}\"\n\ndef analyze_with_llm_direct(prompt, topics=None, provider='claude'):\n    \"\"\"\n    Generate analysis text directly from the LLM based on the provided prompt.\n    This is a simplified version for fallback purposes.\n    \n    Args:\n        prompt: The prompt to send to the LLM\n        topics: Optional list of topics (not used in this function, but kept for API compatibility)\n        provider: 'claude' or 'openai'\n        \n    Returns:\n        The LLM response text\n    \"\"\"\n    if provider == 'openai':\n        client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n        response = client.chat.completions.create(\n            model=\"gpt-4.1-2025-04-14\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are an AI consultant helping summarize newsletter content.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        return response.choices[0].message.content\n    else:  # Default to Claude\n        client = anthropic.Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n        response = client.messages.create(\n            model=\"claude-3-7-sonnet-20250219\",\n            max_tokens=3000,\n            system=\"You are an AI consultant helping summarize newsletter content.\",\n            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        return response.content[0].text